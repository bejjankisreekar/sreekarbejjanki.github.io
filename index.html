
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sreekar Bejjanki | Data Engineer</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>

    <header>
        <h1>Sreekar Bejjanki</h1>
        <p>Data Engineer | Python Â· SQL Â· Databricks Â· Airflow</p>
    </header>

    <section id="about">
        <h2>About Me</h2>
        <p>I am a Data Engineer with over 2 years of experience in designing, developing, and automating data workflows using tools like Python, SQL, Airflow, and Databricks. I specialize in transforming raw healthcare data into actionable insights using modern data platforms.</p>
    </section>

    <section id="experience">
        <h2>Work Experience</h2>

        <div>
            <h3>Datalysys Software Solutions Pvt. Ltd.</h3>
            <p><strong>Role:</strong> Data Engineer</p>
            <p><strong>Duration:</strong> June 2022 â€“ Present</p>
            <p><strong>Location:</strong> Hyderabad (Remote)</p>

            <h4>ðŸ“Œ Patient Messaging Automation Platform</h4>
            <ul>
                <li>Developed 5+ Databricks notebooks to automate SMS messaging workflows for healthcare use cases.</li>
                <li>Utilized PySpark to ingest and transform patient data for message eligibility and scheduling.</li>
                <li>Integrated Twilio API to send real-time SMS notifications and capture delivery status.</li>
                <li>Secured credential access using Azure Key Vault and Unity Catalog-based secrets management.</li>
                <li>Executed SQL Server stored procedures to retrieve dynamic configurations and log message activity.</li>
            </ul>

            <h4>ðŸ“Œ FHIR Data Lake Integration â€“ Unified Patient 360 Pipeline</h4>
            <ul>
                <li>Built Databricks pipelines to ingest and flatten FHIR resources (Patient, Vitals, Appointments).</li>
                <li>Parsed HL7 FHIR JSON into structured PySpark DataFrames using custom extractors.</li>
                <li>Consolidated data into Delta tables with Unity Catalog for secure access and governance.</li>
                <li>Applied CDC logic using Delta MERGE with deduplication on MRN and Encounter ID.</li>
                <li>Processed 1M+ records with optimized batch loads and schema validation.</li>
                <li>Scheduled workflows as production Databricks jobs for continuous and reliable execution.</li>
            </ul>

            <h4>ðŸ“Œ Optimized Data Workflows with PySpark</h4>
            <ul>
                <li>Designed and optimized distributed ETL pipelines using PySpark, reducing processing time by 50%.</li>
                <li>Streamlined data loading, transformation, and real-time analytics in Databricks.</li>
            </ul>
        </div>
    </section>

    <section id="contact">
        <h2>Contact</h2>
        <ul>
            <li>Email: <a href="mailto:sreekarbejjanki@gmail.com">sreekarbejjanki@gmail.com</a></li>
            <li>LinkedIn: <a href="https://linkedin.com/in/sreekarbejjanki">linkedin.com/in/sreekarbejjanki</a></li>
            <li>GitHub: <a href="https://github.com/sreekarbejjanki">github.com/sreekarbejjanki</a></li>
        </ul>
    </section>

</body>
</html>
